{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/25/h4h_hr5535g3kclczsqww0880000gn/T/ipykernel_20672/1235108827.py:22: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[group_1_columns] = df[group_1_columns].applymap(lambda x: 1 if x == '1' else 0)\n",
      "/var/folders/25/h4h_hr5535g3kclczsqww0880000gn/T/ipykernel_20672/1235108827.py:23: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[group_2_columns] = df[group_2_columns].applymap(lambda x: 1 if x == '1' else 0)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 112\u001b[0m\n\u001b[1;32m    109\u001b[0m         list_2_match \u001b[38;5;241m=\u001b[39m count_unique_matches(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLIST_2\u001b[39m\u001b[38;5;124m'\u001b[39m], list_1_reference)\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mSeries([list_1_match, list_2_match])\n\u001b[0;32m--> 112\u001b[0m df_final[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLIST_1_MATCH_COUNT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLIST_2_MATCH_COUNT\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_final\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalculate_match_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Reorder and rename based on the first level of cognitive load\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreorder_based_on_cognitive_load\u001b[39m(row):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[1], line 108\u001b[0m, in \u001b[0;36mcalculate_match_counts\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m    106\u001b[0m     list_2_match \u001b[38;5;241m=\u001b[39m count_unique_matches(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLIST_2\u001b[39m\u001b[38;5;124m'\u001b[39m], list_2_reference)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 108\u001b[0m     list_1_match \u001b[38;5;241m=\u001b[39m \u001b[43mcount_unique_matches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLIST_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlist_2_reference\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     list_2_match \u001b[38;5;241m=\u001b[39m count_unique_matches(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLIST_2\u001b[39m\u001b[38;5;124m'\u001b[39m], list_1_reference)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mSeries([list_1_match, list_2_match])\n",
      "Cell \u001b[0;32mIn[1], line 96\u001b[0m, in \u001b[0;36mcount_unique_matches\u001b[0;34m(recalled_list, reference_list)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount_unique_matches\u001b[39m(recalled_list, reference_list):\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# Tokenize the recalled list (splitting on spaces, commas, and other punctuation)\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m     recalled_words \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mrecalled_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m())\n\u001b[1;32m     97\u001b[0m     recalled_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(recalled_words)\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# Count matches with the reference list\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'raw_0819.csv'\n",
    "df = pd.read_csv(file_path, header=None)\n",
    "\n",
    "# Use the first row as the header (column names)\n",
    "df.columns = df.iloc[0]\n",
    "\n",
    "# Drop the first three rows (including the now redundant header row)\n",
    "df = df.drop([0, 1, 2])\n",
    "\n",
    "# Reset the index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Define the two groups of columns for accuracy calculation\n",
    "group_1_columns = ['Q39', 'Q107', 'Q111', 'Q114', 'Q117', 'Q119', 'Q123', 'Q126', 'Q129', 'Q131']\n",
    "group_2_columns = ['Q180', 'Q184', 'Q188', 'Q191', 'Q194', 'Q197', 'Q200', 'Q202', 'Q206', 'Q209']\n",
    "\n",
    "# Convert values to 1 or 0 based on the condition\n",
    "df[group_1_columns] = df[group_1_columns].applymap(lambda x: 1 if x == '1' else 0)\n",
    "df[group_2_columns] = df[group_2_columns].applymap(lambda x: 1 if x == '1' else 0)\n",
    "\n",
    "# Calculate the group accuracies\n",
    "df['GROUP_1_LC_ACCURACY'] = df[group_1_columns].mean(axis=1)\n",
    "df['GROUP_2_LC_ACCURACY'] = df[group_2_columns].mean(axis=1)\n",
    "\n",
    "# Define the additional columns you want to keep\n",
    "additional_columns = [\n",
    "    'Q1', 'Q2', 'Q3', 'Q5', 'Q6', 'Q173', 'Q214', \n",
    "    'LEVEL_OF_EMOTIONAL_AROUSAL', 'FIRST_LEVEL_OF_COGNITIVE_LOAD', 'FIRST_WORD_LIST'\n",
    "]\n",
    "\n",
    "# Combine the additional columns with the accuracy columns\n",
    "final_columns = additional_columns + ['GROUP_1_LC_ACCURACY', 'GROUP_2_LC_ACCURACY']\n",
    "\n",
    "# Keep only the required columns\n",
    "df_final = df[final_columns]\n",
    "\n",
    "# Rename the columns according to the specified conventions\n",
    "rename_mapping = {\n",
    "    'Q1': 'INITIALS',\n",
    "    'Q2': 'GENDER',\n",
    "    'Q3': 'AGE',\n",
    "    'Q5': 'VISION',\n",
    "    'Q6': 'HEARING',\n",
    "    'Q173': 'LIST_1',\n",
    "    'Q214': 'LIST_2',\n",
    "    'LEVEL_OF_EMOTIONAL_AROUSAL': 'LEVEL_OF_EMOTIONAL_AROUSAL',\n",
    "    'FIRST_LEVEL_OF_COGNITIVE_LOAD': 'FIRST_LEVEL_OF_COGNITIVE_LOAD',\n",
    "    'FIRST_WORD_LIST': 'FIRST_WORD_LIST',\n",
    "    'GROUP_1_LC_ACCURACY': 'GROUP_1_LC_ACCURACY',\n",
    "    'GROUP_2_LC_ACCURACY': 'GROUP_2_LC_ACCURACY'\n",
    "}\n",
    "\n",
    "# Apply the renaming\n",
    "df_final = df_final.rename(columns=rename_mapping)\n",
    "\n",
    "# Ensure all columns are in uppercase with underscores\n",
    "df_final.columns = [col.upper().replace(' ', '_') for col in df_final.columns]\n",
    "\n",
    "# Capitalize initials and remove spaces\n",
    "df_final['INITIALS'] = df_final['INITIALS'].str.replace(\" \", \"\").str.upper()\n",
    "\n",
    "# Normalize gender values\n",
    "def normalize_gender(value):\n",
    "    if value.lower().startswith('f'):\n",
    "        return 'F'\n",
    "    elif value.lower().startswith('m'):\n",
    "        return 'M'\n",
    "    else:\n",
    "        return 'OTHER'\n",
    "\n",
    "df_final['GENDER'] = df_final['GENDER'].apply(normalize_gender)\n",
    "\n",
    "# Convert vision and hearing columns to true/false\n",
    "def normalize_vision_hearing(value):\n",
    "    return 'TRUE' if value in ['1', '2'] else 'FALSE'\n",
    "\n",
    "df_final['VISION'] = df_final['VISION'].apply(normalize_vision_hearing)\n",
    "df_final['HEARING'] = df_final['HEARING'].apply(normalize_vision_hearing)\n",
    "\n",
    "# Reference word lists\n",
    "list_1_reference = [\n",
    "    \"mountain\", \"speaker\", \"wheelchair\", \"glass\", \"house\", \"fork\", \"spouse\", \"juice\", \n",
    "    \"classroom\", \"shoe\", \"bodega\", \"baseball\", \"lumberjack\", \"cloud\", \"armadillo\"]\n",
    "\n",
    "list_2_reference = [\n",
    "    \"pants\", \"tequila\", \"grass\", \"bell\", \"helmet\", \"tortilla\", \"ambulance\", \"bicep\", \n",
    "    \"purple\", \"tornado\", \"recycling\", \"carnival\", \"spectate\", \"giraffe\", \"roommate\"]\n",
    "\n",
    "# Function to count unique matches with better tokenization\n",
    "def count_unique_matches(recalled_list, reference_list):\n",
    "    # Tokenize the recalled list (splitting on spaces, commas, and other punctuation)\n",
    "    recalled_words = re.findall(r'\\b\\w+\\b', recalled_list.lower())\n",
    "    recalled_set = set(recalled_words)\n",
    "    \n",
    "    # Count matches with the reference list\n",
    "    return len(recalled_set.intersection(reference_list))\n",
    "\n",
    "# Calculate the word match counts\n",
    "def calculate_match_counts(row):\n",
    "    if row['FIRST_WORD_LIST'] == '1':\n",
    "        list_1_match = count_unique_matches(row['LIST_1'], list_1_reference)\n",
    "        list_2_match = count_unique_matches(row['LIST_2'], list_2_reference)\n",
    "    else:\n",
    "        list_1_match = count_unique_matches(row['LIST_1'], list_2_reference)\n",
    "        list_2_match = count_unique_matches(row['LIST_2'], list_1_reference)\n",
    "    return pd.Series([list_1_match, list_2_match])\n",
    "\n",
    "df_final[['LIST_1_MATCH_COUNT', 'LIST_2_MATCH_COUNT']] = df_final.apply(calculate_match_counts, axis=1)\n",
    "\n",
    "# Reorder and rename based on the first level of cognitive load\n",
    "def reorder_based_on_cognitive_load(row):\n",
    "    if row['FIRST_LEVEL_OF_COGNITIVE_LOAD'].lower() == 'low':\n",
    "        return pd.Series({\n",
    "            'LOW_COGNITIVE_LOAD_ACCURACY': row['GROUP_1_LC_ACCURACY'],\n",
    "            'HIGH_COGNITIVE_LOAD_ACCURACY': row['GROUP_2_LC_ACCURACY'],\n",
    "            'LOW_COGNITIVE_LOAD_MATCH_COUNT': row['LIST_1_MATCH_COUNT'],\n",
    "            'HIGH_COGNITIVE_LOAD_MATCH_COUNT': row['LIST_2_MATCH_COUNT']\n",
    "        })\n",
    "    else:\n",
    "        return pd.Series({\n",
    "            'LOW_COGNITIVE_LOAD_ACCURACY': row['GROUP_2_LC_ACCURACY'],\n",
    "            'HIGH_COGNITIVE_LOAD_ACCURACY': row['GROUP_1_LC_ACCURACY'],\n",
    "            'LOW_COGNITIVE_LOAD_MATCH_COUNT': row['LIST_2_MATCH_COUNT'],\n",
    "            'HIGH_COGNITIVE_LOAD_MATCH_COUNT': row['LIST_1_MATCH_COUNT']\n",
    "        })\n",
    "\n",
    "df_final[['LOW_COGNITIVE_LOAD_ACCURACY', 'HIGH_COGNITIVE_LOAD_ACCURACY', 'LOW_COGNITIVE_LOAD_MATCH_COUNT', 'HIGH_COGNITIVE_LOAD_MATCH_COUNT']] = df_final.apply(reorder_based_on_cognitive_load, axis=1)\n",
    "\n",
    "# Drop the old columns after reordering\n",
    "df_final = df_final.drop(columns=['GROUP_1_LC_ACCURACY', 'GROUP_2_LC_ACCURACY', 'LIST_1_MATCH_COUNT', 'LIST_2_MATCH_COUNT'])\n",
    "\n",
    "# Prepare the first sheet (essential information)\n",
    "sheet1_columns = [\n",
    "    'INITIALS', 'GENDER', 'AGE', 'VISION', 'HEARING', 'LEVEL_OF_EMOTIONAL_AROUSAL',\n",
    "    'LOW_COGNITIVE_LOAD_ACCURACY', 'HIGH_COGNITIVE_LOAD_ACCURACY',\n",
    "    'LOW_COGNITIVE_LOAD_MATCH_COUNT', 'HIGH_COGNITIVE_LOAD_MATCH_COUNT'\n",
    "]\n",
    "sheet1 = df_final[sheet1_columns]\n",
    "\n",
    "# Prepare the second sheet (detailed information)\n",
    "sheet2_columns = [\n",
    "    'INITIALS', 'GENDER', 'AGE', 'VISION', 'HEARING', 'LIST_1', 'LIST_2',\n",
    "    'LEVEL_OF_EMOTIONAL_AROUSAL', 'FIRST_LEVEL_OF_COGNITIVE_LOAD', 'FIRST_WORD_LIST',\n",
    "    'LOW_COGNITIVE_LOAD_ACCURACY', 'HIGH_COGNITIVE_LOAD_ACCURACY',\n",
    "    'LOW_COGNITIVE_LOAD_MATCH_COUNT', 'HIGH_COGNITIVE_LOAD_MATCH_COUNT'\n",
    "]\n",
    "sheet2 = df_final[sheet2_columns]\n",
    "\n",
    "# Write both sheets to an Excel file\n",
    "with pd.ExcelWriter('preprocessed_data.xlsx') as writer:\n",
    "    sheet1.to_excel(writer, sheet_name='Essential Information', index=False)\n",
    "    sheet2.to_excel(writer, sheet_name='Detailed Information', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Between subject effect not yet supported!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 29\u001b[0m\n\u001b[1;32m     23\u001b[0m df_anova[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOGNITIVE_LOAD\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_anova[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOGNITIVE_LOAD\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap({\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOW_COGNITIVE_LOAD_ACCURACY\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLow\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHIGH_COGNITIVE_LOAD_ACCURACY\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHigh\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     26\u001b[0m })\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Conduct 2-way mixed measures ANOVA\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m anova_model \u001b[38;5;241m=\u001b[39m \u001b[43mAnovaRM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_anova\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mACCURACY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mINITIALS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwithin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCOGNITIVE_LOAD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbetween\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLEVEL_OF_EMOTIONAL_AROUSAL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m anova_results \u001b[38;5;241m=\u001b[39m anova_model\u001b[38;5;241m.\u001b[39mfit()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Collect results\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/stats/anova.py:491\u001b[0m, in \u001b[0;36mAnovaRM.__init__\u001b[0;34m(self, data, depvar, subject, within, between, aggregate_func)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbetween \u001b[38;5;241m=\u001b[39m between\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m between \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBetween subject effect not \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    492\u001b[0m                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myet supported!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubject \u001b[38;5;241m=\u001b[39m subject\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aggregate_func \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Between subject effect not yet supported!"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "\n",
    "# Load the existing Excel file\n",
    "file_path = 'preprocessed_data.xlsx'\n",
    "df_final = pd.read_excel(file_path, sheet_name='Detailed Information')\n",
    "\n",
    "# Calculate Means\n",
    "mean_stats = df_final[['LOW_COGNITIVE_LOAD_ACCURACY', 'HIGH_COGNITIVE_LOAD_ACCURACY', \n",
    "                       'LOW_COGNITIVE_LOAD_MATCH_COUNT', 'HIGH_COGNITIVE_LOAD_MATCH_COUNT']].mean()\n",
    "\n",
    "# Prepare the data for ANOVA\n",
    "# Melt the data to long format for ANOVA\n",
    "df_anova = pd.melt(df_final, \n",
    "                   id_vars=['INITIALS', 'GENDER', 'AGE', 'VISION', 'HEARING', 'LEVEL_OF_EMOTIONAL_AROUSAL'], \n",
    "                   value_vars=['LOW_COGNITIVE_LOAD_ACCURACY', 'HIGH_COGNITIVE_LOAD_ACCURACY'], \n",
    "                   var_name='COGNITIVE_LOAD', \n",
    "                   value_name='ACCURACY')\n",
    "\n",
    "# Map cognitive load to low/high for simplicity\n",
    "df_anova['COGNITIVE_LOAD'] = df_anova['COGNITIVE_LOAD'].map({\n",
    "    'LOW_COGNITIVE_LOAD_ACCURACY': 'Low', \n",
    "    'HIGH_COGNITIVE_LOAD_ACCURACY': 'High'\n",
    "})\n",
    "\n",
    "# Conduct 2-way mixed measures ANOVA\n",
    "anova_model = AnovaRM(df_anova, 'ACCURACY', 'INITIALS', within=['COGNITIVE_LOAD'], between=['LEVEL_OF_EMOTIONAL_AROUSAL'])\n",
    "anova_results = anova_model.fit()\n",
    "\n",
    "# Collect results\n",
    "anova_table = anova_results.summary().tables[0].as_html()\n",
    "anova_df = pd.read_html(anova_table, header=0, index_col=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the output Excel file\n",
    "with pd.ExcelWriter(file_path, mode='a', if_sheet_exists='new') as writer:\n",
    "    # Write the mean statistics to a new sheet\n",
    "    mean_stats.to_excel(writer, sheet_name='Mean Statistics', index=True)\n",
    "\n",
    "    # Write the ANOVA results to another new sheet\n",
    "    anova_df.to_excel(writer, sheet_name='ANOVA Results', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
